{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"demonetization\" \n",
    "number = 10000\n",
    "filename = \"demonetization-tweets_Clusters.csv\"\n",
    "file_count = \"demonetization-tweets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the encoding of the data file\n",
    "import chardet\n",
    "with open('./demonetization-tweets.csv','rb') as f:\n",
    "    result = chardet.detect(f.read())  #Windows-1252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'Windows-1252', 'confidence': 0.73, 'language': ''}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Clean the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data file\n",
    "df = pd.read_csv(\"./\"+file_count+\".csv\", encoding=result['encoding'])\n",
    "df = df[1:number+1]\n",
    "df = df['text']\n",
    "df = pd.DataFrame({'tweet':df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @ANI_news: Gurugram (Haryana): Post office ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>@DerekScissors1: India’s #demonetization: #Bla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "1  RT @Hemant_80: Did you vote on #Demonetization...\n",
       "2  RT @roshankar: Former FinSec, RBI Dy Governor,...\n",
       "3  RT @ANI_news: Gurugram (Haryana): Post office ...\n",
       "4  RT @satishacharya: Reddy Wedding! @mail_today ...\n",
       "5  @DerekScissors1: India’s #demonetization: #Bla..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the tweets\n",
    "df['cleaned_tweet'] = df['tweet'].replace(r'\\'|\\\"|\\,|\\.|\\?|\\+|\\-|\\/|\\=|\\(|\\)|\\n|\"', '', regex=True)\n",
    "df['cleaned_tweet'] = df['cleaned_tweet'].replace(\"  \", \" \")\n",
    "\n",
    "words_remove = [\"ax\",\"i\",\"you\",\"edu\",\"s\",\"t\",\"m\",\"subject\",\"can\",\"lines\",\"re\",\"what\", \"there\",\"all\",\"we\",\n",
    "                \"one\",\"the\",\"a\",\"an\",\"of\",\"or\",\"in\",\"for\",\"by\",\"on\",\"but\",\"is\",\"in\",\"a\",\"not\",\"with\",\"as\",\n",
    "                \"was\",\"if\",\"they\",\"are\",\"this\",\"and\",\"it\",\"have\",\"has\",\"from\",\"at\",\"my\",\"be\",\"by\",\"not\",\"that\",\"to\",\n",
    "                \"from\",\"com\",\"org\",\"like\",\"likes\",\"so\",\"said\",\"from\",\"what\",\"told\",\"over\",\"more\",\"other\",\n",
    "                \"have\",\"last\",\"with\",\"this\",\"that\",\"such\",\"when\",\"been\",\"says\",\"will\",\"also\",\"where\",\"why\",\n",
    "                \"would\",\"today\", \"in\", \"on\", \"you\", \"r\", \"d\", \"u\", \"hw\",\"wat\", \"oly\", \"s\", \"b\", \"ht\", \n",
    "                \"rt\", \"p\",\"the\",\"th\", \"n\", \"was\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantext(df, words_to_remove = words_remove): \n",
    "    ### dont change the original tweet\n",
    "    # remove emoticons form the tweets\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'<ed>','', regex = True)\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'\\B<U+.*>|<U+.*>\\B|<U+.*>','', regex = True)\n",
    "    \n",
    "    # convert tweets to lowercase\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].str.lower()\n",
    "    \n",
    "    #remove user mentions\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'^(@\\w+)',\"\", regex=True)\n",
    "    \n",
    "    #remove 'rt' in the beginning\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'^(rt @)',\"\", regex=True)\n",
    "    \n",
    "    #remove_symbols\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'[^a-zA-Z0-9]', \" \", regex=True)\n",
    "\n",
    "    #remove punctuations \n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'[[]!\"#$%\\'()\\*+,-./:;<=>?^_`{|}]+',\"\", regex = True)\n",
    "\n",
    "    #remove_URL(x):\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'https.*$', \"\", regex = True)\n",
    "\n",
    "    #remove 'amp' in the text\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'amp',\"\", regex = True)\n",
    "    \n",
    "    #remove words of length 1 or 2 \n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'\\b[a-zA-Z]{1,2}\\b','', regex=True)\n",
    "\n",
    "    #remove extra spaces in the tweet\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'^\\s+|\\s+$',\" \", regex=True)\n",
    "     \n",
    "    \n",
    "    #remove stopwords and words_to_remove\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    mystopwords = [stop_words, \"via\", words_to_remove]\n",
    "    \n",
    "    df['fully_cleaned_tweet'] = df['cleaned_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in mystopwords]))\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BhagavanReddy\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\inference.py:239: FutureWarning: Possible nested set at position 1\n",
      "  re.compile(obj)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization...</td>\n",
       "      <td>hemant 80  did you vote   demonetization  modi...</td>\n",
       "      <td>hemant 80 did you vote demonetization modi sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor,...</td>\n",
       "      <td>roshankar  former finsec rbi  governor cbdt ch...</td>\n",
       "      <td>roshankar former finsec rbi governor cbdt chai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @ANI_news: Gurugram (Haryana): Post office ...</td>\n",
       "      <td>ani news  gurugram haryana  post office employ...</td>\n",
       "      <td>ani news gurugram haryana post office employee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today ...</td>\n",
       "      <td>satishacharya  reddy wedding   mail today cart...</td>\n",
       "      <td>satishacharya reddy wedding mail today cartoon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>@DerekScissors1: India’s #demonetization: #Bla...</td>\n",
       "      <td>india   demonetization   blackmoney  symptom ...</td>\n",
       "      <td>india demonetization blackmoney symptom not th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "1  RT @Hemant_80: Did you vote on #Demonetization...   \n",
       "2  RT @roshankar: Former FinSec, RBI Dy Governor,...   \n",
       "3  RT @ANI_news: Gurugram (Haryana): Post office ...   \n",
       "4  RT @satishacharya: Reddy Wedding! @mail_today ...   \n",
       "5  @DerekScissors1: India’s #demonetization: #Bla...   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "1  hemant 80  did you vote   demonetization  modi...   \n",
       "2  roshankar  former finsec rbi  governor cbdt ch...   \n",
       "3  ani news  gurugram haryana  post office employ...   \n",
       "4  satishacharya  reddy wedding   mail today cart...   \n",
       "5   india   demonetization   blackmoney  symptom ...   \n",
       "\n",
       "                                 fully_cleaned_tweet  \n",
       "1  hemant 80 did you vote demonetization modi sur...  \n",
       "2  roshankar former finsec rbi governor cbdt chai...  \n",
       "3  ani news gurugram haryana post office employee...  \n",
       "4  satishacharya reddy wedding mail today cartoon...  \n",
       "5  india demonetization blackmoney symptom not th...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the processed tweets\n",
    "df = cleantext(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading https://files.pythonhosted.org/packages/60/f0/1d9bfcc8ee6b83472ec571406bd0dd51c0e6330ff1a51b2d29861d389e85/textblob-0.15.3-py2.py3-none-any.whl (636kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\bhagavanreddy\\anaconda3\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\bhagavanreddy\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis\n",
    "from textblob import TextBlob\n",
    "df['sentiment'] = df['fully_cleaned_tweet'].apply(lambda x: TextBlob(x).sentiment.polarity)  #-1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization...</td>\n",
       "      <td>hemant 80  did you vote   demonetization  modi...</td>\n",
       "      <td>hemant 80 did you vote demonetization modi sur...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor,...</td>\n",
       "      <td>roshankar  former finsec rbi  governor cbdt ch...</td>\n",
       "      <td>roshankar former finsec rbi governor cbdt chai...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @ANI_news: Gurugram (Haryana): Post office ...</td>\n",
       "      <td>ani news  gurugram haryana  post office employ...</td>\n",
       "      <td>ani news gurugram haryana post office employee...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today ...</td>\n",
       "      <td>satishacharya  reddy wedding   mail today cart...</td>\n",
       "      <td>satishacharya reddy wedding mail today cartoon...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>@DerekScissors1: India’s #demonetization: #Bla...</td>\n",
       "      <td>india   demonetization   blackmoney  symptom ...</td>\n",
       "      <td>india demonetization blackmoney symptom not th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "1  RT @Hemant_80: Did you vote on #Demonetization...   \n",
       "2  RT @roshankar: Former FinSec, RBI Dy Governor,...   \n",
       "3  RT @ANI_news: Gurugram (Haryana): Post office ...   \n",
       "4  RT @satishacharya: Reddy Wedding! @mail_today ...   \n",
       "5  @DerekScissors1: India’s #demonetization: #Bla...   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "1  hemant 80  did you vote   demonetization  modi...   \n",
       "2  roshankar  former finsec rbi  governor cbdt ch...   \n",
       "3  ani news  gurugram haryana  post office employ...   \n",
       "4  satishacharya  reddy wedding   mail today cart...   \n",
       "5   india   demonetization   blackmoney  symptom ...   \n",
       "\n",
       "                                 fully_cleaned_tweet  sentiment  \n",
       "1  hemant 80 did you vote demonetization modi sur...        0.0  \n",
       "2  roshankar former finsec rbi governor cbdt chai...        0.0  \n",
       "3  ani news gurugram haryana post office employee...        0.0  \n",
       "4  satishacharya reddy wedding mail today cartoon...        0.0  \n",
       "5  india demonetization blackmoney symptom not th...        0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Vectorize the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization...</td>\n",
       "      <td>hemant 80  did you vote   demonetization  modi...</td>\n",
       "      <td>hemant 80 did you vote demonetization modi sur...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[hemant, 80, did, you, vote, demonetization, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor,...</td>\n",
       "      <td>roshankar  former finsec rbi  governor cbdt ch...</td>\n",
       "      <td>roshankar former finsec rbi governor cbdt chai...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[roshankar, former, finsec, rbi, governor, cbd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @ANI_news: Gurugram (Haryana): Post office ...</td>\n",
       "      <td>ani news  gurugram haryana  post office employ...</td>\n",
       "      <td>ani news gurugram haryana post office employee...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ani, news, gurugram, haryana, post, office, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today ...</td>\n",
       "      <td>satishacharya  reddy wedding   mail today cart...</td>\n",
       "      <td>satishacharya reddy wedding mail today cartoon...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[satishacharya, reddy, wedding, mail, today, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>@DerekScissors1: India’s #demonetization: #Bla...</td>\n",
       "      <td>india   demonetization   blackmoney  symptom ...</td>\n",
       "      <td>india demonetization blackmoney symptom not th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[india, demonetization, blackmoney, symptom, n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "1  RT @Hemant_80: Did you vote on #Demonetization...   \n",
       "2  RT @roshankar: Former FinSec, RBI Dy Governor,...   \n",
       "3  RT @ANI_news: Gurugram (Haryana): Post office ...   \n",
       "4  RT @satishacharya: Reddy Wedding! @mail_today ...   \n",
       "5  @DerekScissors1: India’s #demonetization: #Bla...   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "1  hemant 80  did you vote   demonetization  modi...   \n",
       "2  roshankar  former finsec rbi  governor cbdt ch...   \n",
       "3  ani news  gurugram haryana  post office employ...   \n",
       "4  satishacharya  reddy wedding   mail today cart...   \n",
       "5   india   demonetization   blackmoney  symptom ...   \n",
       "\n",
       "                                 fully_cleaned_tweet  sentiment  \\\n",
       "1  hemant 80 did you vote demonetization modi sur...        0.0   \n",
       "2  roshankar former finsec rbi governor cbdt chai...        0.0   \n",
       "3  ani news gurugram haryana post office employee...        0.0   \n",
       "4  satishacharya reddy wedding mail today cartoon...        0.0   \n",
       "5  india demonetization blackmoney symptom not th...        0.0   \n",
       "\n",
       "                                     tokenized_tweet  \n",
       "1  [hemant, 80, did, you, vote, demonetization, m...  \n",
       "2  [roshankar, former, finsec, rbi, governor, cbd...  \n",
       "3  [ani, news, gurugram, haryana, post, office, e...  \n",
       "4  [satishacharya, reddy, wedding, mail, today, c...  \n",
       "5  [india, demonetization, blackmoney, symptom, n...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_tweet'] = df['fully_cleaned_tweet'].apply(word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if a word has a digit, remove that word\n",
    "df['tokenized_tweet'] = df['tokenized_tweet'].apply(lambda x: [y for y in x if not any(c.isdigit() for c in y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 100    # Word vector dimensionality                      \n",
    "min_word_count = 1   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(df['tokenized_tweet'], workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=7652, size=100, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BhagavanReddy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.01849402,  0.11456431,  0.15560867, -0.10890228, -0.09181392,\n",
       "        0.10000034, -0.04142923,  0.0160463 ,  0.00058721, -0.12933941,\n",
       "       -0.05741211, -0.11873823,  0.0970791 ,  0.12387466,  0.18476829,\n",
       "       -0.13852133, -0.04183862,  0.07700722, -0.14404123,  0.08503724,\n",
       "       -0.11037641,  0.05916216,  0.00923787, -0.05201008, -0.12971872,\n",
       "        0.012409  ,  0.1403049 , -0.22167183,  0.03262706,  0.0381026 ,\n",
       "        0.03285928, -0.00338404,  0.02319512, -0.02338156, -0.0084332 ,\n",
       "        0.00465545,  0.01385034,  0.18238716,  0.150967  , -0.10211366,\n",
       "       -0.23472099, -0.04840574,  0.05870393, -0.00891721, -0.1449757 ,\n",
       "        0.02450378,  0.04257541,  0.08848149,  0.01166491, -0.0021478 ,\n",
       "        0.0930557 ,  0.046371  ,  0.16386081,  0.0321661 , -0.11081693,\n",
       "        0.08191402,  0.0402762 , -0.07332906,  0.00054731,  0.18398537,\n",
       "       -0.16737825, -0.21648459,  0.05894341,  0.017719  ,  0.12901856,\n",
       "       -0.05735436, -0.01162308,  0.11199737, -0.01410391, -0.09746891,\n",
       "        0.11924773,  0.2138717 ,  0.02182202, -0.00932156,  0.06138062,\n",
       "        0.14014618, -0.06000383, -0.0261555 , -0.16452192,  0.09597958,\n",
       "        0.13280667,  0.06577221, -0.0964853 , -0.0051695 , -0.16429561,\n",
       "        0.14956582, -0.02517417, -0.01887405,  0.00391744, -0.08662598,\n",
       "       -0.0942673 ,  0.0961393 ,  0.07247976, -0.04963222,  0.03905781,\n",
       "        0.0518094 ,  0.13254386,  0.11782178,  0.06424077,  0.12350893],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model)\n",
    "model['hemant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find vector corresponding to each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the average of all word vectors in a tweet\n",
    "import numpy as np\n",
    "vocab = list(model.wv.vocab)\n",
    "def sentence_vector(sentence, model):\n",
    "    nwords = 0\n",
    "    featureV = np.zeros(100, dtype=\"float32\")\n",
    "    for word in sentence:\n",
    "        if word not in vocab:\n",
    "            continue\n",
    "        featureV = np.add(featureV, model[word])\n",
    "        nwords = nwords + 1\n",
    "    if nwords > 0: \n",
    "        featureV = np.divide(featureV, nwords)\n",
    "    return featureV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BhagavanReddy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.145178</td>\n",
       "      <td>0.147514</td>\n",
       "      <td>-0.069161</td>\n",
       "      <td>-0.067178</td>\n",
       "      <td>0.079719</td>\n",
       "      <td>-0.050528</td>\n",
       "      <td>0.011328</td>\n",
       "      <td>0.033261</td>\n",
       "      <td>-0.135008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086182</td>\n",
       "      <td>0.108031</td>\n",
       "      <td>0.086109</td>\n",
       "      <td>-0.056946</td>\n",
       "      <td>0.025146</td>\n",
       "      <td>0.046597</td>\n",
       "      <td>0.133032</td>\n",
       "      <td>0.105447</td>\n",
       "      <td>0.057718</td>\n",
       "      <td>0.122388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.050099</td>\n",
       "      <td>-0.009989</td>\n",
       "      <td>0.195613</td>\n",
       "      <td>-0.007635</td>\n",
       "      <td>-0.083550</td>\n",
       "      <td>0.091357</td>\n",
       "      <td>-0.049674</td>\n",
       "      <td>-0.021680</td>\n",
       "      <td>-0.034829</td>\n",
       "      <td>-0.062094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140587</td>\n",
       "      <td>0.161284</td>\n",
       "      <td>0.050666</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.042011</td>\n",
       "      <td>0.051530</td>\n",
       "      <td>0.102566</td>\n",
       "      <td>0.150345</td>\n",
       "      <td>0.028524</td>\n",
       "      <td>0.308597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.065409</td>\n",
       "      <td>0.014514</td>\n",
       "      <td>0.209758</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>-0.064745</td>\n",
       "      <td>0.083866</td>\n",
       "      <td>-0.046320</td>\n",
       "      <td>-0.019571</td>\n",
       "      <td>-0.022617</td>\n",
       "      <td>-0.064024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125582</td>\n",
       "      <td>0.137329</td>\n",
       "      <td>0.057194</td>\n",
       "      <td>0.022022</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.048947</td>\n",
       "      <td>0.075539</td>\n",
       "      <td>0.144824</td>\n",
       "      <td>0.030367</td>\n",
       "      <td>0.327682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.054286</td>\n",
       "      <td>-0.026542</td>\n",
       "      <td>0.170636</td>\n",
       "      <td>-0.085281</td>\n",
       "      <td>-0.082708</td>\n",
       "      <td>0.103345</td>\n",
       "      <td>-0.053977</td>\n",
       "      <td>-0.038898</td>\n",
       "      <td>-0.012208</td>\n",
       "      <td>-0.031153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115264</td>\n",
       "      <td>0.126924</td>\n",
       "      <td>0.035904</td>\n",
       "      <td>-0.019648</td>\n",
       "      <td>0.023975</td>\n",
       "      <td>0.023249</td>\n",
       "      <td>0.082649</td>\n",
       "      <td>0.113520</td>\n",
       "      <td>0.020971</td>\n",
       "      <td>0.251372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.087156</td>\n",
       "      <td>0.042076</td>\n",
       "      <td>0.164309</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>-0.036794</td>\n",
       "      <td>0.025005</td>\n",
       "      <td>-0.046114</td>\n",
       "      <td>-0.006224</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>-0.072754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084652</td>\n",
       "      <td>0.118738</td>\n",
       "      <td>0.055630</td>\n",
       "      <td>0.027680</td>\n",
       "      <td>0.028533</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.052109</td>\n",
       "      <td>0.127632</td>\n",
       "      <td>0.015594</td>\n",
       "      <td>0.242863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>0.057474</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.171483</td>\n",
       "      <td>-0.074609</td>\n",
       "      <td>-0.083344</td>\n",
       "      <td>0.101339</td>\n",
       "      <td>-0.076492</td>\n",
       "      <td>-0.041278</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>-0.057157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110283</td>\n",
       "      <td>0.149861</td>\n",
       "      <td>0.055882</td>\n",
       "      <td>-0.018538</td>\n",
       "      <td>-0.026981</td>\n",
       "      <td>0.070641</td>\n",
       "      <td>0.145886</td>\n",
       "      <td>0.102768</td>\n",
       "      <td>0.080955</td>\n",
       "      <td>0.206910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>-0.012201</td>\n",
       "      <td>0.058777</td>\n",
       "      <td>0.079949</td>\n",
       "      <td>-0.101394</td>\n",
       "      <td>-0.096331</td>\n",
       "      <td>0.066315</td>\n",
       "      <td>-0.058465</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>-0.152532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130359</td>\n",
       "      <td>0.095423</td>\n",
       "      <td>0.026217</td>\n",
       "      <td>-0.077861</td>\n",
       "      <td>0.057959</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.100299</td>\n",
       "      <td>0.104382</td>\n",
       "      <td>0.036243</td>\n",
       "      <td>0.111875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>0.057474</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.171483</td>\n",
       "      <td>-0.074609</td>\n",
       "      <td>-0.083344</td>\n",
       "      <td>0.101339</td>\n",
       "      <td>-0.076492</td>\n",
       "      <td>-0.041278</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>-0.057157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110283</td>\n",
       "      <td>0.149861</td>\n",
       "      <td>0.055882</td>\n",
       "      <td>-0.018538</td>\n",
       "      <td>-0.026981</td>\n",
       "      <td>0.070641</td>\n",
       "      <td>0.145886</td>\n",
       "      <td>0.102768</td>\n",
       "      <td>0.080955</td>\n",
       "      <td>0.206910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>0.057474</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.171483</td>\n",
       "      <td>-0.074609</td>\n",
       "      <td>-0.083344</td>\n",
       "      <td>0.101339</td>\n",
       "      <td>-0.076492</td>\n",
       "      <td>-0.041278</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>-0.057157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110283</td>\n",
       "      <td>0.149861</td>\n",
       "      <td>0.055882</td>\n",
       "      <td>-0.018538</td>\n",
       "      <td>-0.026981</td>\n",
       "      <td>0.070641</td>\n",
       "      <td>0.145886</td>\n",
       "      <td>0.102768</td>\n",
       "      <td>0.080955</td>\n",
       "      <td>0.206910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>-0.017444</td>\n",
       "      <td>0.031257</td>\n",
       "      <td>0.232946</td>\n",
       "      <td>0.117560</td>\n",
       "      <td>0.023255</td>\n",
       "      <td>0.147237</td>\n",
       "      <td>-0.051714</td>\n",
       "      <td>-0.003472</td>\n",
       "      <td>-0.026488</td>\n",
       "      <td>-0.011793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057706</td>\n",
       "      <td>0.105606</td>\n",
       "      <td>0.129580</td>\n",
       "      <td>0.088915</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>0.020417</td>\n",
       "      <td>0.135361</td>\n",
       "      <td>-0.026039</td>\n",
       "      <td>0.307834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "1      0.005265  0.145178  0.147514 -0.069161 -0.067178  0.079719 -0.050528   \n",
       "2     -0.050099 -0.009989  0.195613 -0.007635 -0.083550  0.091357 -0.049674   \n",
       "3     -0.065409  0.014514  0.209758  0.000943 -0.064745  0.083866 -0.046320   \n",
       "4     -0.054286 -0.026542  0.170636 -0.085281 -0.082708  0.103345 -0.053977   \n",
       "5     -0.087156  0.042076  0.164309  0.046300 -0.036794  0.025005 -0.046114   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "9996   0.057474  0.000632  0.171483 -0.074609 -0.083344  0.101339 -0.076492   \n",
       "9997  -0.012201  0.058777  0.079949 -0.101394 -0.096331  0.066315 -0.058465   \n",
       "9998   0.057474  0.000632  0.171483 -0.074609 -0.083344  0.101339 -0.076492   \n",
       "9999   0.057474  0.000632  0.171483 -0.074609 -0.083344  0.101339 -0.076492   \n",
       "10000 -0.017444  0.031257  0.232946  0.117560  0.023255  0.147237 -0.051714   \n",
       "\n",
       "             7         8         9   ...        90        91        92  \\\n",
       "1      0.011328  0.033261 -0.135008  ... -0.086182  0.108031  0.086109   \n",
       "2     -0.021680 -0.034829 -0.062094  ... -0.140587  0.161284  0.050666   \n",
       "3     -0.019571 -0.022617 -0.064024  ... -0.125582  0.137329  0.057194   \n",
       "4     -0.038898 -0.012208 -0.031153  ... -0.115264  0.126924  0.035904   \n",
       "5     -0.006224  0.010800 -0.072754  ... -0.084652  0.118738  0.055630   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "9996  -0.041278  0.003894 -0.057157  ... -0.110283  0.149861  0.055882   \n",
       "9997   0.018600  0.008244 -0.152532  ... -0.130359  0.095423  0.026217   \n",
       "9998  -0.041278  0.003894 -0.057157  ... -0.110283  0.149861  0.055882   \n",
       "9999  -0.041278  0.003894 -0.057157  ... -0.110283  0.149861  0.055882   \n",
       "10000 -0.003472 -0.026488 -0.011793  ... -0.057706  0.105606  0.129580   \n",
       "\n",
       "             93        94        95        96        97        98        99  \n",
       "1     -0.056946  0.025146  0.046597  0.133032  0.105447  0.057718  0.122388  \n",
       "2      0.013894  0.042011  0.051530  0.102566  0.150345  0.028524  0.308597  \n",
       "3      0.022022  0.035088  0.048947  0.075539  0.144824  0.030367  0.327682  \n",
       "4     -0.019648  0.023975  0.023249  0.082649  0.113520  0.020971  0.251372  \n",
       "5      0.027680  0.028533  0.002835  0.052109  0.127632  0.015594  0.242863  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "9996  -0.018538 -0.026981  0.070641  0.145886  0.102768  0.080955  0.206910  \n",
       "9997  -0.077861  0.057959  0.055100  0.100299  0.104382  0.036243  0.111875  \n",
       "9998  -0.018538 -0.026981  0.070641  0.145886  0.102768  0.080955  0.206910  \n",
       "9999  -0.018538 -0.026981  0.070641  0.145886  0.102768  0.080955  0.206910  \n",
       "10000  0.088915  0.009156  0.090244  0.020417  0.135361 -0.026039  0.307834  \n",
       "\n",
       "[10000 rows x 100 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_vector = df['tokenized_tweet'].apply(lambda x: sentence_vector(x, model))  \n",
    "tweet_vector = tweet_vector.apply(pd.Series)\n",
    "tweet_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweet vector should vary from 0 to 1 (normalize the vector)\n",
    "for x in range(len(tweet_vector)):\n",
    "    x_min = tweet_vector.iloc[x].min()\n",
    "    x_max = tweet_vector.iloc[x].max()\n",
    "    X  = tweet_vector.iloc[x]\n",
    "    i = 0\n",
    "    if (x_max - x_min) == 0:\n",
    "        for y in X:\n",
    "            tweet_vector.iloc[x][i] = (1/len(tweet_vector.iloc[x]))\n",
    "            i = i + 1\n",
    "    else:\n",
    "        for y in X:\n",
    "            tweet_vector.iloc[x][i] = ((y - x_min)/(x_max - x_min))\n",
    "            i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6   \\\n",
      "1      0.525097  0.843612  0.848932  0.355665  0.360180  0.694594  0.398084   \n",
      "2      0.324409  0.399955  0.787198  0.404388  0.261405  0.590836  0.325210   \n",
      "3      0.293233  0.436933  0.787976  0.412532  0.294428  0.561625  0.327554   \n",
      "4      0.300143  0.359965  0.785131  0.233310  0.238858  0.640036  0.300809   \n",
      "5      0.248238  0.542621  0.821058  0.552243  0.362961  0.503734  0.341729   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "9996   0.583541  0.443594  0.864232  0.258350  0.236844  0.691535  0.253716   \n",
      "9997   0.470926  0.637027  0.686573  0.262201  0.274049  0.654666  0.362662   \n",
      "9998   0.583541  0.443594  0.864232  0.258350  0.236844  0.691535  0.253716   \n",
      "9999   0.583541  0.443594  0.864232  0.258350  0.236844  0.691535  0.253716   \n",
      "10000  0.385479  0.477486  0.858521  0.640531  0.462368  0.696598  0.320735   \n",
      "\n",
      "             7         8         9   ...        90        91        92  \\\n",
      "1      0.538902  0.588831  0.205763  ...  0.316917  0.759048  0.709141   \n",
      "2      0.377935  0.353170  0.301818  ...  0.153978  0.722542  0.514196   \n",
      "3      0.375649  0.370172  0.295723  ...  0.185044  0.657749  0.513670   \n",
      "4      0.333322  0.390874  0.350023  ...  0.168658  0.690877  0.494616   \n",
      "5      0.432595  0.471377  0.281046  ...  0.253942  0.717251  0.573496   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "9996   0.340412  0.451626  0.301318  ...  0.170521  0.810997  0.579620   \n",
      "9997   0.543005  0.518771  0.142528  ...  0.194417  0.722784  0.560831   \n",
      "9998   0.340412  0.451626  0.301318  ...  0.170521  0.810997  0.579620   \n",
      "9999   0.340412  0.451626  0.301318  ...  0.170521  0.810997  0.579620   \n",
      "10000  0.411875  0.368393  0.396154  ...  0.309414  0.617947  0.663238   \n",
      "\n",
      "             93        94        95        96        97        98        99  \n",
      "1      0.383472  0.570357  0.619191  0.815963  0.753164  0.644509  0.791732  \n",
      "2      0.444938  0.497895  0.515823  0.611949  0.701938  0.472493  1.000000  \n",
      "3      0.450432  0.473924  0.498841  0.546655  0.671225  0.465436  1.000000  \n",
      "4      0.374831  0.468893  0.467329  0.595409  0.661975  0.462416  0.959218  \n",
      "5      0.509828  0.511771  0.453232  0.565474  0.737511  0.482297  1.000000  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "9996   0.396399  0.375612  0.615956  0.801211  0.695054  0.641351  0.951453  \n",
      "9997   0.317271  0.635111  0.628423  0.734195  0.743750  0.584293  0.761286  \n",
      "9998   0.396399  0.375612  0.615956  0.801211  0.695054  0.641351  0.951453  \n",
      "9999   0.396399  0.375612  0.615956  0.801211  0.695054  0.641351  0.951453  \n",
      "10000  0.586414  0.435731  0.588924  0.457007  0.674161  0.369240  1.000000  \n",
      "\n",
      "[10000 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tweet_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Add sentiment to the tweet vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the 'sentiment' vector\n",
    "#Sentiment varies from -1 to +1\n",
    "\n",
    "def sentiment(x):\n",
    "    if x < 0.04:\n",
    "        return 0\n",
    "    elif x > 0.04:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.5\n",
    "\n",
    "tweet_vector[100] = df['sentiment'].apply(lambda x: sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.525097</td>\n",
       "      <td>0.843612</td>\n",
       "      <td>0.848932</td>\n",
       "      <td>0.355665</td>\n",
       "      <td>0.360180</td>\n",
       "      <td>0.694594</td>\n",
       "      <td>0.398084</td>\n",
       "      <td>0.538902</td>\n",
       "      <td>0.588831</td>\n",
       "      <td>0.205763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759048</td>\n",
       "      <td>0.709141</td>\n",
       "      <td>0.383472</td>\n",
       "      <td>0.570357</td>\n",
       "      <td>0.619191</td>\n",
       "      <td>0.815963</td>\n",
       "      <td>0.753164</td>\n",
       "      <td>0.644509</td>\n",
       "      <td>0.791732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.324409</td>\n",
       "      <td>0.399955</td>\n",
       "      <td>0.787198</td>\n",
       "      <td>0.404388</td>\n",
       "      <td>0.261405</td>\n",
       "      <td>0.590836</td>\n",
       "      <td>0.325210</td>\n",
       "      <td>0.377935</td>\n",
       "      <td>0.353170</td>\n",
       "      <td>0.301818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722542</td>\n",
       "      <td>0.514196</td>\n",
       "      <td>0.444938</td>\n",
       "      <td>0.497895</td>\n",
       "      <td>0.515823</td>\n",
       "      <td>0.611949</td>\n",
       "      <td>0.701938</td>\n",
       "      <td>0.472493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.293233</td>\n",
       "      <td>0.436933</td>\n",
       "      <td>0.787976</td>\n",
       "      <td>0.412532</td>\n",
       "      <td>0.294428</td>\n",
       "      <td>0.561625</td>\n",
       "      <td>0.327554</td>\n",
       "      <td>0.375649</td>\n",
       "      <td>0.370172</td>\n",
       "      <td>0.295723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657749</td>\n",
       "      <td>0.513670</td>\n",
       "      <td>0.450432</td>\n",
       "      <td>0.473924</td>\n",
       "      <td>0.498841</td>\n",
       "      <td>0.546655</td>\n",
       "      <td>0.671225</td>\n",
       "      <td>0.465436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.300143</td>\n",
       "      <td>0.359965</td>\n",
       "      <td>0.785131</td>\n",
       "      <td>0.233310</td>\n",
       "      <td>0.238858</td>\n",
       "      <td>0.640036</td>\n",
       "      <td>0.300809</td>\n",
       "      <td>0.333322</td>\n",
       "      <td>0.390874</td>\n",
       "      <td>0.350023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690877</td>\n",
       "      <td>0.494616</td>\n",
       "      <td>0.374831</td>\n",
       "      <td>0.468893</td>\n",
       "      <td>0.467329</td>\n",
       "      <td>0.595409</td>\n",
       "      <td>0.661975</td>\n",
       "      <td>0.462416</td>\n",
       "      <td>0.959218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.248238</td>\n",
       "      <td>0.542621</td>\n",
       "      <td>0.821058</td>\n",
       "      <td>0.552243</td>\n",
       "      <td>0.362961</td>\n",
       "      <td>0.503734</td>\n",
       "      <td>0.341729</td>\n",
       "      <td>0.432595</td>\n",
       "      <td>0.471377</td>\n",
       "      <td>0.281046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717251</td>\n",
       "      <td>0.573496</td>\n",
       "      <td>0.509828</td>\n",
       "      <td>0.511771</td>\n",
       "      <td>0.453232</td>\n",
       "      <td>0.565474</td>\n",
       "      <td>0.737511</td>\n",
       "      <td>0.482297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.443594</td>\n",
       "      <td>0.864232</td>\n",
       "      <td>0.258350</td>\n",
       "      <td>0.236844</td>\n",
       "      <td>0.691535</td>\n",
       "      <td>0.253716</td>\n",
       "      <td>0.340412</td>\n",
       "      <td>0.451626</td>\n",
       "      <td>0.301318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810997</td>\n",
       "      <td>0.579620</td>\n",
       "      <td>0.396399</td>\n",
       "      <td>0.375612</td>\n",
       "      <td>0.615956</td>\n",
       "      <td>0.801211</td>\n",
       "      <td>0.695054</td>\n",
       "      <td>0.641351</td>\n",
       "      <td>0.951453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>0.470926</td>\n",
       "      <td>0.637027</td>\n",
       "      <td>0.686573</td>\n",
       "      <td>0.262201</td>\n",
       "      <td>0.274049</td>\n",
       "      <td>0.654666</td>\n",
       "      <td>0.362662</td>\n",
       "      <td>0.543005</td>\n",
       "      <td>0.518771</td>\n",
       "      <td>0.142528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722784</td>\n",
       "      <td>0.560831</td>\n",
       "      <td>0.317271</td>\n",
       "      <td>0.635111</td>\n",
       "      <td>0.628423</td>\n",
       "      <td>0.734195</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.584293</td>\n",
       "      <td>0.761286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.443594</td>\n",
       "      <td>0.864232</td>\n",
       "      <td>0.258350</td>\n",
       "      <td>0.236844</td>\n",
       "      <td>0.691535</td>\n",
       "      <td>0.253716</td>\n",
       "      <td>0.340412</td>\n",
       "      <td>0.451626</td>\n",
       "      <td>0.301318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810997</td>\n",
       "      <td>0.579620</td>\n",
       "      <td>0.396399</td>\n",
       "      <td>0.375612</td>\n",
       "      <td>0.615956</td>\n",
       "      <td>0.801211</td>\n",
       "      <td>0.695054</td>\n",
       "      <td>0.641351</td>\n",
       "      <td>0.951453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.443594</td>\n",
       "      <td>0.864232</td>\n",
       "      <td>0.258350</td>\n",
       "      <td>0.236844</td>\n",
       "      <td>0.691535</td>\n",
       "      <td>0.253716</td>\n",
       "      <td>0.340412</td>\n",
       "      <td>0.451626</td>\n",
       "      <td>0.301318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810997</td>\n",
       "      <td>0.579620</td>\n",
       "      <td>0.396399</td>\n",
       "      <td>0.375612</td>\n",
       "      <td>0.615956</td>\n",
       "      <td>0.801211</td>\n",
       "      <td>0.695054</td>\n",
       "      <td>0.641351</td>\n",
       "      <td>0.951453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.385479</td>\n",
       "      <td>0.477486</td>\n",
       "      <td>0.858521</td>\n",
       "      <td>0.640531</td>\n",
       "      <td>0.462368</td>\n",
       "      <td>0.696598</td>\n",
       "      <td>0.320735</td>\n",
       "      <td>0.411875</td>\n",
       "      <td>0.368393</td>\n",
       "      <td>0.396154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617947</td>\n",
       "      <td>0.663238</td>\n",
       "      <td>0.586414</td>\n",
       "      <td>0.435731</td>\n",
       "      <td>0.588924</td>\n",
       "      <td>0.457007</td>\n",
       "      <td>0.674161</td>\n",
       "      <td>0.369240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "1      0.525097  0.843612  0.848932  0.355665  0.360180  0.694594  0.398084   \n",
       "2      0.324409  0.399955  0.787198  0.404388  0.261405  0.590836  0.325210   \n",
       "3      0.293233  0.436933  0.787976  0.412532  0.294428  0.561625  0.327554   \n",
       "4      0.300143  0.359965  0.785131  0.233310  0.238858  0.640036  0.300809   \n",
       "5      0.248238  0.542621  0.821058  0.552243  0.362961  0.503734  0.341729   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "9996   0.583541  0.443594  0.864232  0.258350  0.236844  0.691535  0.253716   \n",
       "9997   0.470926  0.637027  0.686573  0.262201  0.274049  0.654666  0.362662   \n",
       "9998   0.583541  0.443594  0.864232  0.258350  0.236844  0.691535  0.253716   \n",
       "9999   0.583541  0.443594  0.864232  0.258350  0.236844  0.691535  0.253716   \n",
       "10000  0.385479  0.477486  0.858521  0.640531  0.462368  0.696598  0.320735   \n",
       "\n",
       "            7         8         9    ...       91        92        93   \\\n",
       "1      0.538902  0.588831  0.205763  ...  0.759048  0.709141  0.383472   \n",
       "2      0.377935  0.353170  0.301818  ...  0.722542  0.514196  0.444938   \n",
       "3      0.375649  0.370172  0.295723  ...  0.657749  0.513670  0.450432   \n",
       "4      0.333322  0.390874  0.350023  ...  0.690877  0.494616  0.374831   \n",
       "5      0.432595  0.471377  0.281046  ...  0.717251  0.573496  0.509828   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "9996   0.340412  0.451626  0.301318  ...  0.810997  0.579620  0.396399   \n",
       "9997   0.543005  0.518771  0.142528  ...  0.722784  0.560831  0.317271   \n",
       "9998   0.340412  0.451626  0.301318  ...  0.810997  0.579620  0.396399   \n",
       "9999   0.340412  0.451626  0.301318  ...  0.810997  0.579620  0.396399   \n",
       "10000  0.411875  0.368393  0.396154  ...  0.617947  0.663238  0.586414   \n",
       "\n",
       "            94        95        96        97        98        99   100  \n",
       "1      0.570357  0.619191  0.815963  0.753164  0.644509  0.791732    0  \n",
       "2      0.497895  0.515823  0.611949  0.701938  0.472493  1.000000    0  \n",
       "3      0.473924  0.498841  0.546655  0.671225  0.465436  1.000000    0  \n",
       "4      0.468893  0.467329  0.595409  0.661975  0.462416  0.959218    0  \n",
       "5      0.511771  0.453232  0.565474  0.737511  0.482297  1.000000    0  \n",
       "...         ...       ...       ...       ...       ...       ...  ...  \n",
       "9996   0.375612  0.615956  0.801211  0.695054  0.641351  0.951453    1  \n",
       "9997   0.635111  0.628423  0.734195  0.743750  0.584293  0.761286    1  \n",
       "9998   0.375612  0.615956  0.801211  0.695054  0.641351  0.951453    1  \n",
       "9999   0.375612  0.615956  0.801211  0.695054  0.641351  0.951453    1  \n",
       "10000  0.435731  0.588924  0.457007  0.674161  0.369240  1.000000    0  \n",
       "\n",
       "[10000 rows x 101 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_vector  #sentiment 0 to +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating the 'sentiment' column in df also\n",
    "df['sentiment'] = tweet_vector[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Cluster the narratives [= opinions + expressions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = [4, 5, 6, 7, 8, 9, 10, 11]\n",
    "X = tweet_vector\n",
    "n_best_clusters = 0\n",
    "silhouette_best = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 4 The average silhouette_score is : 0.2359700194167453\n",
      "For n_clusters = 5 The average silhouette_score is : 0.2507793763173987\n",
      "For n_clusters = 6 The average silhouette_score is : 0.25837742981133377\n",
      "For n_clusters = 7 The average silhouette_score is : 0.2694055595261788\n",
      "For n_clusters = 8 The average silhouette_score is : 0.29659779189975005\n",
      "For n_clusters = 9 The average silhouette_score is : 0.30308841567776906\n",
      "For n_clusters = 10 The average silhouette_score is : 0.3037191199973398\n",
      "For n_clusters = 11 The average silhouette_score is : 0.30266046984779454\n"
     ]
    }
   ],
   "source": [
    "for n_clusters in range_n_clusters:\n",
    "    \n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "                                      #, sample_size = 5000)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "    \n",
    "    if silhouette_avg > silhouette_best:\n",
    "        silhouette_best = silhouette_avg\n",
    "        n_best_clusters = n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = KMeans(n_clusters= n_best_clusters , random_state=10)\n",
    "cluster_labels = clusterer.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(cluster_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array of tweets, the corresponding cluster number, sentiment\n",
    "finaldf = pd.DataFrame({'cl_num': cluster_labels,'fully_cleaned_tweet': df['fully_cleaned_tweet'], 'cleaned_tweet': df['cleaned_tweet'], 'tweet': df['tweet'],'sentiment': df['sentiment']})\n",
    "finaldf = finaldf.sort_values(by=['cl_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cl_num'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>cl_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization...</td>\n",
       "      <td>hemant 80  did you vote   demonetization  modi...</td>\n",
       "      <td>hemant 80 did you vote demonetization modi sur...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hemant, did, you, vote, demonetization, modi,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor,...</td>\n",
       "      <td>roshankar  former finsec rbi  governor cbdt ch...</td>\n",
       "      <td>roshankar former finsec rbi governor cbdt chai...</td>\n",
       "      <td>0</td>\n",
       "      <td>[roshankar, former, finsec, rbi, governor, cbd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @ANI_news: Gurugram (Haryana): Post office ...</td>\n",
       "      <td>ani news  gurugram haryana  post office employ...</td>\n",
       "      <td>ani news gurugram haryana post office employee...</td>\n",
       "      <td>0</td>\n",
       "      <td>[ani, news, gurugram, haryana, post, office, e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today ...</td>\n",
       "      <td>satishacharya  reddy wedding   mail today cart...</td>\n",
       "      <td>satishacharya reddy wedding mail today cartoon...</td>\n",
       "      <td>0</td>\n",
       "      <td>[satishacharya, reddy, wedding, mail, today, c...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>@DerekScissors1: India’s #demonetization: #Bla...</td>\n",
       "      <td>india   demonetization   blackmoney  symptom ...</td>\n",
       "      <td>india demonetization blackmoney symptom not th...</td>\n",
       "      <td>0</td>\n",
       "      <td>[india, demonetization, blackmoney, symptom, n...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>RT @AdityaNair20: First time in 29years, our M...</td>\n",
       "      <td>adityanair20  first time  29years our milkman ...</td>\n",
       "      <td>adityanair20 first time 29years our milkman as...</td>\n",
       "      <td>1</td>\n",
       "      <td>[first, time, our, milkman, asked, for, check,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>RT @URautelaForever: Dear @evanspiegel \\r\\nInd...</td>\n",
       "      <td>urautelaforever  dear  evanspiegel  india   ri...</td>\n",
       "      <td>urautelaforever dear evanspiegel india rich th...</td>\n",
       "      <td>1</td>\n",
       "      <td>[urautelaforever, dear, evanspiegel, india, ri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>RT @AdityaNair20: First time in 29years, our M...</td>\n",
       "      <td>adityanair20  first time  29years our milkman ...</td>\n",
       "      <td>adityanair20 first time 29years our milkman as...</td>\n",
       "      <td>1</td>\n",
       "      <td>[first, time, our, milkman, asked, for, check,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>RT @AdityaNair20: First time in 29years, our M...</td>\n",
       "      <td>adityanair20  first time  29years our milkman ...</td>\n",
       "      <td>adityanair20 first time 29years our milkman as...</td>\n",
       "      <td>1</td>\n",
       "      <td>[first, time, our, milkman, asked, for, check,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>RT @priyaakulkarni2: Post demonetization\\r\\n\\r...</td>\n",
       "      <td>priyaakulkarni2  post demonetization  economy ...</td>\n",
       "      <td>priyaakulkarni2 post demonetization economy gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[post, demonetization, economy, grow, acc, asi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  \\\n",
       "1      RT @Hemant_80: Did you vote on #Demonetization...   \n",
       "2      RT @roshankar: Former FinSec, RBI Dy Governor,...   \n",
       "3      RT @ANI_news: Gurugram (Haryana): Post office ...   \n",
       "4      RT @satishacharya: Reddy Wedding! @mail_today ...   \n",
       "5      @DerekScissors1: India’s #demonetization: #Bla...   \n",
       "...                                                  ...   \n",
       "9996   RT @AdityaNair20: First time in 29years, our M...   \n",
       "9997   RT @URautelaForever: Dear @evanspiegel \\r\\nInd...   \n",
       "9998   RT @AdityaNair20: First time in 29years, our M...   \n",
       "9999   RT @AdityaNair20: First time in 29years, our M...   \n",
       "10000  RT @priyaakulkarni2: Post demonetization\\r\\n\\r...   \n",
       "\n",
       "                                           cleaned_tweet  \\\n",
       "1      hemant 80  did you vote   demonetization  modi...   \n",
       "2      roshankar  former finsec rbi  governor cbdt ch...   \n",
       "3      ani news  gurugram haryana  post office employ...   \n",
       "4      satishacharya  reddy wedding   mail today cart...   \n",
       "5       india   demonetization   blackmoney  symptom ...   \n",
       "...                                                  ...   \n",
       "9996   adityanair20  first time  29years our milkman ...   \n",
       "9997   urautelaforever  dear  evanspiegel  india   ri...   \n",
       "9998   adityanair20  first time  29years our milkman ...   \n",
       "9999   adityanair20  first time  29years our milkman ...   \n",
       "10000  priyaakulkarni2  post demonetization  economy ...   \n",
       "\n",
       "                                     fully_cleaned_tweet  sentiment  \\\n",
       "1      hemant 80 did you vote demonetization modi sur...          0   \n",
       "2      roshankar former finsec rbi governor cbdt chai...          0   \n",
       "3      ani news gurugram haryana post office employee...          0   \n",
       "4      satishacharya reddy wedding mail today cartoon...          0   \n",
       "5      india demonetization blackmoney symptom not th...          0   \n",
       "...                                                  ...        ...   \n",
       "9996   adityanair20 first time 29years our milkman as...          1   \n",
       "9997   urautelaforever dear evanspiegel india rich th...          1   \n",
       "9998   adityanair20 first time 29years our milkman as...          1   \n",
       "9999   adityanair20 first time 29years our milkman as...          1   \n",
       "10000  priyaakulkarni2 post demonetization economy gr...          0   \n",
       "\n",
       "                                         tokenized_tweet  cl_num  \n",
       "1      [hemant, did, you, vote, demonetization, modi,...       3  \n",
       "2      [roshankar, former, finsec, rbi, governor, cbd...       1  \n",
       "3      [ani, news, gurugram, haryana, post, office, e...       1  \n",
       "4      [satishacharya, reddy, wedding, mail, today, c...       7  \n",
       "5      [india, demonetization, blackmoney, symptom, n...       6  \n",
       "...                                                  ...     ...  \n",
       "9996   [first, time, our, milkman, asked, for, check,...       0  \n",
       "9997   [urautelaforever, dear, evanspiegel, india, ri...       0  \n",
       "9998   [first, time, our, milkman, asked, for, check,...       0  \n",
       "9999   [first, time, our, milkman, asked, for, check,...       0  \n",
       "10000  [post, demonetization, economy, grow, acc, asi...       2  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOrdered = pd.DataFrame(df)\n",
    "\n",
    "#Compute how many times a tweet has been 'retweeted' - that is, how many rows in dfOrdered are identical\n",
    "dfOrdered['tokenized_tweet'] = dfOrdered['tokenized_tweet'].apply(tuple)\n",
    "dfUnique = dfOrdered.groupby(['tweet', 'cleaned_tweet', 'fully_cleaned_tweet', 'sentiment','tokenized_tweet', 'cl_num']).size().reset_index(name=\"freq\")\n",
    "dfUnique = dfUnique.sort_values(by=['cl_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUnique['tokenized_tweet'] = dfUnique['tokenized_tweet'].apply(list)\n",
    "dfOrdered['tokenized_tweet'] = dfOrdered['tokenized_tweet'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>cl_num</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2307</td>\n",
       "      <td>RT @SwachhPolitics: #Demonetization\\r\\nCan't b...</td>\n",
       "      <td>swachhpolitics   demonetization cant believe p...</td>\n",
       "      <td>swachhpolitics demonetization cant believe peo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[swachhpolitics, demonetization, cant, believe...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1711</td>\n",
       "      <td>Months after #DeMonetization, many #ATMs conti...</td>\n",
       "      <td>months after  demonetization many  atms contin...</td>\n",
       "      <td>months after demonetization many atms continue...</td>\n",
       "      <td>1</td>\n",
       "      <td>[months, after, demonetization, many, atms, co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>Modi’s Demonetization was not a Failure, prove...</td>\n",
       "      <td>modi  demonetization was not  failure proves m...</td>\n",
       "      <td>modi demonetization was not failure proves man...</td>\n",
       "      <td>1</td>\n",
       "      <td>[modi, demonetization, was, not, failure, prov...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1705</td>\n",
       "      <td>Modi's #DeMonetization was actually a strategy...</td>\n",
       "      <td>modis  demonetization was actually  strategy  ...</td>\n",
       "      <td>modis demonetization was actually strategy bri...</td>\n",
       "      <td>1</td>\n",
       "      <td>[modis, demonetization, was, actually, strateg...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2751</td>\n",
       "      <td>RT @rashmitambe: What exactly is problem in ad...</td>\n",
       "      <td>rashmitambe  what exactly  problem  addressing...</td>\n",
       "      <td>rashmitambe what exactly problem addressing pa...</td>\n",
       "      <td>1</td>\n",
       "      <td>[rashmitambe, what, exactly, problem, addressi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1332</td>\n",
       "      <td>Everyone seems to hate the rich, even the rich...</td>\n",
       "      <td>everyone seems  hate the rich even the rich ha...</td>\n",
       "      <td>everyone seems hate the rich even the rich hat...</td>\n",
       "      <td>0</td>\n",
       "      <td>[everyone, seems, hate, the, rich, even, the, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>By the time the Opposition finishes with its n...</td>\n",
       "      <td>the time the opposition finishes with its nau...</td>\n",
       "      <td>the time the opposition finishes with its naut...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, time, the, opposition, finishes, with, i...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2798</td>\n",
       "      <td>RT @saxenask352: 95% sacrificing to cleanse 5%...</td>\n",
       "      <td>saxenask352  95  sacrificing  cleanse 5  benef...</td>\n",
       "      <td>saxenask352 95 sacrificing cleanse 5 benefits ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[sacrificing, cleanse, benefits, demonetizatio...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2981</td>\n",
       "      <td>Shiva Sena and SAD fall in line with the gover...</td>\n",
       "      <td>shiva sena and sad fall  line with the governm...</td>\n",
       "      <td>shiva sena and sad fall line with the governme...</td>\n",
       "      <td>0</td>\n",
       "      <td>[shiva, sena, and, sad, fall, line, with, the,...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581</td>\n",
       "      <td>@CNNnews18 all the morons who bark \"how good D...</td>\n",
       "      <td>all the morons who bark how good demonetizati...</td>\n",
       "      <td>all the morons who bark how good demonetizatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>[all, the, morons, who, bark, how, good, demon...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3485 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  \\\n",
       "2307  RT @SwachhPolitics: #Demonetization\\r\\nCan't b...   \n",
       "1711  Months after #DeMonetization, many #ATMs conti...   \n",
       "1710  Modi’s Demonetization was not a Failure, prove...   \n",
       "1705  Modi's #DeMonetization was actually a strategy...   \n",
       "2751  RT @rashmitambe: What exactly is problem in ad...   \n",
       "...                                                 ...   \n",
       "1332  Everyone seems to hate the rich, even the rich...   \n",
       "1175  By the time the Opposition finishes with its n...   \n",
       "2798  RT @saxenask352: 95% sacrificing to cleanse 5%...   \n",
       "2981  Shiva Sena and SAD fall in line with the gover...   \n",
       "581   @CNNnews18 all the morons who bark \"how good D...   \n",
       "\n",
       "                                          cleaned_tweet  \\\n",
       "2307  swachhpolitics   demonetization cant believe p...   \n",
       "1711  months after  demonetization many  atms contin...   \n",
       "1710  modi  demonetization was not  failure proves m...   \n",
       "1705  modis  demonetization was actually  strategy  ...   \n",
       "2751  rashmitambe  what exactly  problem  addressing...   \n",
       "...                                                 ...   \n",
       "1332  everyone seems  hate the rich even the rich ha...   \n",
       "1175   the time the opposition finishes with its nau...   \n",
       "2798  saxenask352  95  sacrificing  cleanse 5  benef...   \n",
       "2981  shiva sena and sad fall  line with the governm...   \n",
       "581    all the morons who bark how good demonetizati...   \n",
       "\n",
       "                                    fully_cleaned_tweet  sentiment  \\\n",
       "2307  swachhpolitics demonetization cant believe peo...          1   \n",
       "1711  months after demonetization many atms continue...          1   \n",
       "1710  modi demonetization was not failure proves man...          1   \n",
       "1705  modis demonetization was actually strategy bri...          1   \n",
       "2751  rashmitambe what exactly problem addressing pa...          1   \n",
       "...                                                 ...        ...   \n",
       "1332  everyone seems hate the rich even the rich hat...          0   \n",
       "1175  the time the opposition finishes with its naut...          0   \n",
       "2798  saxenask352 95 sacrificing cleanse 5 benefits ...          0   \n",
       "2981  shiva sena and sad fall line with the governme...          0   \n",
       "581   all the morons who bark how good demonetizatio...          0   \n",
       "\n",
       "                                        tokenized_tweet  cl_num  freq  \n",
       "2307  [swachhpolitics, demonetization, cant, believe...       0     3  \n",
       "1711  [months, after, demonetization, many, atms, co...       0     1  \n",
       "1710  [modi, demonetization, was, not, failure, prov...       0     1  \n",
       "1705  [modis, demonetization, was, actually, strateg...       0     1  \n",
       "2751  [rashmitambe, what, exactly, problem, addressi...       0     1  \n",
       "...                                                 ...     ...   ...  \n",
       "1332  [everyone, seems, hate, the, rich, even, the, ...       9     1  \n",
       "1175  [the, time, the, opposition, finishes, with, i...       9     1  \n",
       "2798  [sacrificing, cleanse, benefits, demonetizatio...       9     1  \n",
       "2981  [shiva, sena, and, sad, fall, line, with, the,...       9     1  \n",
       "581   [all, the, morons, who, bark, how, good, demon...       9     1  \n",
       "\n",
       "[3485 rows x 7 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUnique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discard the clusters with poor Silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(X, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38434295, 0.49248217, 0.52784359, ..., 0.20879619, 0.20879619,\n",
       "       0.4797031 ])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_silhouette_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 : 0.17641072213642167\n",
      "Cluster 1 : 0.3394631070186884\n",
      "Cluster 2 : 0.3974449093377233\n",
      "Cluster 3 : 0.1680751858026234\n",
      "Cluster 4 : 0.24000622092279547\n",
      "Cluster 5 : 0.5386852489147615\n",
      "Cluster 6 : 0.0500566773070515\n",
      "Cluster 7 : 0.3746520006627592\n",
      "Cluster 8 : 0.3760914784156285\n",
      "Cluster 9 : 0.5527857710094498\n"
     ]
    }
   ],
   "source": [
    "poor_cluster_indices = []\n",
    "avg_cluster_sil_score = []\n",
    "\n",
    "for i in range(n_best_clusters):\n",
    "# Aggregate the silhouette scores for samples belonging to\n",
    "# cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "        avgscore = (np.mean(ith_cluster_silhouette_values))   #average silhouette score for each cluster\n",
    "        avg_cluster_sil_score = np.append(avg_cluster_sil_score, avgscore)\n",
    "        print('Cluster',i, ':', avgscore)\n",
    "        if avgscore < 0.2:\n",
    "            poor_cluster_indices = np.append(poor_cluster_indices, i)\n",
    "            \n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 3., 6.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poor_cluster_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove those rows where cluster value match poor_cluster_indices \n",
    "avg_cluster_sil_score_final = []\n",
    "cluster_name = np.unique(dfOrdered['cl_num'])\n",
    "\n",
    "if (len(poor_cluster_indices)!=0):\n",
    "    n_final_clusters = n_best_clusters - len(poor_cluster_indices)\n",
    "    for i in poor_cluster_indices:\n",
    "        dfUnique = dfUnique[dfUnique['cl_num'] != i]\n",
    "    for j in cluster_name:\n",
    "        if j not in poor_cluster_indices:    \n",
    "            avg_cluster_sil_score_final = np.append(avg_cluster_sil_score_final, avg_cluster_sil_score[j])\n",
    "            \n",
    "    cluster_name = np.unique(dfUnique['cl_num'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUnique['cl_num'] = abs(dfUnique['cl_num'])\n",
    "dfUnique = dfUnique.sort_values(by=['cl_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Calculate abstraction and expression for each narrative\n",
    "\n",
    "Note that each cluster represents a narrative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
